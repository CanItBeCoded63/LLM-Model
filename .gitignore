import os
import re
import nltk
import csv
import torch
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from transformers import BertTokenizer, BertForQuestionAnswering

nltk.download('stopwords')
nltk.download('punkt')

notes = []
path = r'//directory of your stored file
for file_name in os.listdir(path):
    if file_name.endswith('.txt'):
        with open(os.path.join(path, file_name), 'r') as file:
            note = file.read()
            note = re.sub(r'[^a-zA-Z0-9\s]', '', note)
            note = re.sub(r'\s+',' ', note)
            notes.append(note.strip())

questions = []
answers = []
new_path = r'//directory of your stored file
with open(new_path, 'r') as file:
    reader = csv.reader(file)
    for line in reader:
        questions.append(line[0])
        answers.append(line[1])

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')

def answer_question(question, context):
    max_length = 804
    inputs = tokenizer(question, context, return_tensors='pt', truncation=True, max_length=max_length)
    start_scores, end_scores = model(**inputs).values()

    start_index = torch.argmax(start_scores)
    end_index = torch.argmax(end_scores)

    answer_tokens = inputs['input_ids'][0][start_index:end_index+1]
    answer = tokenizer.decode(answer_tokens)

    return answer

def answer_question_interactively():
    while True:
        question = input("Please enter your question (or type 'exit' to quit): ")
        
        if question.lower() == 'exit':
            print("Exiting...")
            break
        
        best_answer = None
        best_score = float('-inf')
        for i, context in enumerate(notes):
            generated_answer = answer_question(question, context)
            print(f"Generated Answer for context {i + 1}: {generated_answer}")
            
            scores = model(**tokenizer(question, context, return_tensors="pt")).values()
            confidence_score = torch.max(torch.stack(tuple(scores))).item()
            if confidence_score > best_score:
                best_answer = generated_answer
                best_score = confidence_score
        
        print(f"\nBest Answer: {best_answer}\n")


answer_question_interactively()4
